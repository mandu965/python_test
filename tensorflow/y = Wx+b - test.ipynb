{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 28.835752 [-1.4594582] [-0.06135748]\n",
      "20 0.35575938 [0.44315144] [0.72764117]\n",
      "40 0.08888296 [0.6394805] [0.76829803]\n",
      "60 0.0786013 [0.672626] [0.7393183]\n",
      "80 0.07136768 [0.68955415] [0.70525163]\n",
      "100 0.06481711 [0.7042909] [0.67217195]\n",
      "120 0.058867883 [0.7182022] [0.64058846]\n",
      "140 0.053464726 [0.7314471] [0.6104835]\n",
      "160 0.04855753 [0.7440682] [0.5817931]\n",
      "180 0.04410069 [0.756096] [0.5544509]\n",
      "200 0.040053003 [0.7675586] [0.52839386]\n",
      "220 0.036376745 [0.77848256] [0.5035614]\n",
      "240 0.03303798 [0.78889304] [0.47989586]\n",
      "260 0.030005606 [0.7988143] [0.4573425]\n",
      "280 0.027251584 [0.8082692] [0.43584913]\n",
      "300 0.024750328 [0.81727993] [0.41536582]\n",
      "320 0.022478634 [0.82586706] [0.3958451]\n",
      "340 0.020415442 [0.83405066] [0.37724176]\n",
      "360 0.018541655 [0.84184974] [0.35951284]\n",
      "380 0.016839808 [0.8492822] [0.342617]\n",
      "400 0.01529419 [0.8563653] [0.32651526]\n",
      "420 0.013890426 [0.86311567] [0.31117028]\n",
      "440 0.012615506 [0.86954874] [0.2965464]\n",
      "460 0.01145761 [0.87567943] [0.28260985]\n",
      "480 0.010406 [0.88152206] [0.26932824]\n",
      "500 0.009450895 [0.8870901] [0.2566708]\n",
      "520 0.008583439 [0.89239645] [0.24460821]\n",
      "540 0.007795615 [0.8974534] [0.23311253]\n",
      "560 0.0070801117 [0.9022727] [0.22215708]\n",
      "580 0.006430265 [0.9068655] [0.21171653]\n",
      "600 0.0058400654 [0.91124254] [0.20176664]\n",
      "620 0.005304054 [0.9154138] [0.19228438]\n",
      "640 0.0048172153 [0.91938907] [0.18324772]\n",
      "660 0.0043750717 [0.9231775] [0.1746357]\n",
      "680 0.0039735143 [0.9267878] [0.16642848]\n",
      "700 0.0036088035 [0.93022853] [0.1586069]\n",
      "720 0.0032775744 [0.9335075] [0.151153]\n",
      "740 0.0029767433 [0.93663245] [0.14404936]\n",
      "760 0.0027035282 [0.9396105] [0.13727956]\n",
      "780 0.002455388 [0.9424486] [0.13082792]\n",
      "800 0.0022300207 [0.94515324] [0.1246795]\n",
      "820 0.0020253442 [0.94773084] [0.11882003]\n",
      "840 0.0018394473 [0.9501873] [0.11323592]\n",
      "860 0.0016706189 [0.9525283] [0.10791425]\n",
      "880 0.0015172831 [0.95475936] [0.10284268]\n",
      "900 0.001378019 [0.95688546] [0.09800944]\n",
      "920 0.0012515438 [0.9589116] [0.09340337]\n",
      "940 0.0011366667 [0.9608427] [0.08901379]\n",
      "960 0.0010323417 [0.96268296] [0.08483046]\n",
      "980 0.00093759084 [0.9644367] [0.08084376]\n",
      "1000 0.0008515334 [0.966108] [0.07704441]\n",
      "1020 0.00077337836 [0.96770084] [0.0734236]\n",
      "1040 0.0007023934 [0.96921873] [0.06997299]\n",
      "1060 0.0006379236 [0.97066545] [0.06668449]\n",
      "1080 0.00057937443 [0.972044] [0.06355055]\n",
      "1100 0.0005261966 [0.97335786] [0.0605639]\n",
      "1120 0.00047789948 [0.9746099] [0.05771761]\n",
      "1140 0.00043403605 [0.9758032] [0.05500508]\n",
      "1160 0.00039419797 [0.97694033] [0.05242004]\n",
      "1180 0.0003580152 [0.97802407] [0.04995648]\n",
      "1200 0.00032515594 [0.97905684] [0.04760873]\n",
      "1220 0.000295311 [0.9800412] [0.04537127]\n",
      "1240 0.00026820778 [0.98097914] [0.04323893]\n",
      "1260 0.00024358917 [0.98187304] [0.04120687]\n",
      "1280 0.00022123125 [0.9827249] [0.0392703]\n",
      "1300 0.00020092535 [0.9835368] [0.03742475]\n",
      "1320 0.00018248381 [0.98431045] [0.03566595]\n",
      "1340 0.00016573531 [0.9850478] [0.0339898]\n",
      "1360 0.00015052342 [0.9857505] [0.03239239]\n",
      "1380 0.00013670797 [0.98642015] [0.0308701]\n",
      "1400 0.00012416116 [0.98705834] [0.02941934]\n",
      "1420 0.00011276436 [0.9876666] [0.02803674]\n",
      "1440 0.00010241489 [0.9882462] [0.02671911]\n",
      "1460 9.301573e-05 [0.98879856] [0.02546341]\n",
      "1480 8.447756e-05 [0.98932505] [0.02426677]\n",
      "1500 7.6725366e-05 [0.98982656] [0.02312638]\n",
      "1520 6.9682654e-05 [0.9903049] [0.02203953]\n",
      "1540 6.3286054e-05 [0.99076045] [0.02100371]\n",
      "1560 5.7477737e-05 [0.99119467] [0.02001658]\n",
      "1580 5.2202584e-05 [0.9916085] [0.01907586]\n",
      "1600 4.741148e-05 [0.99200284] [0.01817938]\n",
      "1620 4.305963e-05 [0.9923787] [0.01732501]\n",
      "1640 3.910711e-05 [0.9927369] [0.0165108]\n",
      "1660 3.551788e-05 [0.99307823] [0.01573487]\n",
      "1680 3.225716e-05 [0.99340355] [0.01499538]\n",
      "1700 2.9297049e-05 [0.9937135] [0.01429065]\n",
      "1720 2.6608226e-05 [0.994009] [0.01361902]\n",
      "1740 2.4165665e-05 [0.99429053] [0.01297895]\n",
      "1760 2.194765e-05 [0.9945589] [0.01236898]\n",
      "1780 1.993361e-05 [0.9948146] [0.01178771]\n",
      "1800 1.8103367e-05 [0.99505836] [0.01123369]\n",
      "1820 1.6441862e-05 [0.9952905] [0.01070573]\n",
      "1840 1.4932487e-05 [0.99551183] [0.01020261]\n",
      "1860 1.3562385e-05 [0.9957228] [0.00972313]\n",
      "1880 1.2317803e-05 [0.99592376] [0.00926621]\n",
      "1900 1.1186887e-05 [0.9961153] [0.00883073]\n",
      "1920 1.0160325e-05 [0.9962979] [0.00841572]\n",
      "1940 9.227566e-06 [0.9964719] [0.00802022]\n",
      "1960 8.381107e-06 [0.9966377] [0.0076433]\n",
      "1980 7.611304e-06 [0.9967957] [0.00728408]\n",
      "2000 6.9128237e-06 [0.9969463] [0.00694177]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# X and Y data\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Our hypothesis XW+b\n",
    "hypothesis = x_train * W + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line\n",
    "for step in range(2001):\n",
    "   sess.run(train)\n",
    "   if step % 20 == 0:\n",
    "       print(step, sess.run(cost), sess.run(W), sess.run(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 29.598322 [-0.35370526] [0.06864211]\n",
      "20 0.05967912 [1.1509225] [0.52838826]\n",
      "40 0.05159208 [1.1474341] [0.5675951]\n",
      "60 0.045055747 [1.1378075] [0.60247076]\n",
      "80 0.039347522 [1.1287825] [0.63505435]\n",
      "100 0.034362487 [1.1203485] [0.665504]\n",
      "120 0.030009026 [1.1124667] [0.6939594]\n",
      "140 0.026207108 [1.1051012] [0.72055125]\n",
      "160 0.022886863 [1.0982181] [0.74540156]\n",
      "180 0.01998726 [1.0917856] [0.7686246]\n",
      "200 0.017455015 [1.0857745] [0.79032665]\n",
      "220 0.015243617 [1.080157] [0.8106074]\n",
      "240 0.013312343 [1.0749075] [0.8295599]\n",
      "260 0.011625775 [1.0700017] [0.84727126]\n",
      "280 0.010152884 [1.0654173] [0.8638227]\n",
      "300 0.008866578 [1.061133] [0.8792901]\n",
      "320 0.0077432604 [1.0571294] [0.8937445]\n",
      "340 0.006762246 [1.053388] [0.9072524]\n",
      "360 0.0059055123 [1.0498915] [0.9198756]\n",
      "380 0.0051573277 [1.0466241] [0.93167216]\n",
      "400 0.004503931 [1.0435706] [0.94269603]\n",
      "420 0.003933317 [1.040717] [0.9529981]\n",
      "440 0.0034349984 [1.0380505] [0.9626254]\n",
      "460 0.002999803 [1.0355586] [0.9716222]\n",
      "480 0.002619748 [1.0332297] [0.9800297]\n",
      "500 0.0022878428 [1.0310535] [0.9878866]\n",
      "520 0.0019979961 [1.0290198] [0.995229]\n",
      "540 0.0017448564 [1.0271193] [1.0020906]\n",
      "560 0.001523809 [1.0253433] [1.0085027]\n",
      "580 0.0013307495 [1.0236835] [1.0144949]\n",
      "600 0.0011621641 [1.0221326] [1.0200944]\n",
      "620 0.0010149314 [1.020683] [1.0253274]\n",
      "640 0.00088634156 [1.0193285] [1.0302178]\n",
      "660 0.00077405473 [1.0180627] [1.0347877]\n",
      "680 0.00067599275 [1.0168798] [1.0390584]\n",
      "700 0.00059034314 [1.0157744] [1.0430497]\n",
      "720 0.0005155508 [1.0147412] [1.0467794]\n",
      "740 0.00045023742 [1.013776] [1.0502646]\n",
      "760 0.00039319173 [1.0128736] [1.053522]\n",
      "780 0.00034338067 [1.0120306] [1.0565658]\n",
      "800 0.0002998803 [1.0112427] [1.0594103]\n",
      "820 0.0002618858 [1.0105065] [1.0620685]\n",
      "840 0.0002287091 [1.0098184] [1.0645524]\n",
      "860 0.00019973202 [1.0091753] [1.066874]\n",
      "880 0.00017442877 [1.0085744] [1.0690435]\n",
      "900 0.00015232743 [1.0080129] [1.0710708]\n",
      "920 0.00013303109 [1.0074881] [1.0729654]\n",
      "940 0.00011617462 [1.0069977] [1.0747359]\n",
      "960 0.00010145678 [1.0065395] [1.0763904]\n",
      "980 8.8603745e-05 [1.0061111] [1.0779366]\n",
      "1000 7.737905e-05 [1.005711] [1.0793817]\n",
      "1020 6.757321e-05 [1.0053369] [1.080732]\n",
      "1040 5.901428e-05 [1.0049875] [1.0819937]\n",
      "1060 5.153661e-05 [1.0046607] [1.0831729]\n",
      "1080 4.5007553e-05 [1.0043555] [1.0842749]\n",
      "1100 3.9306244e-05 [1.0040703] [1.0853047]\n",
      "1120 3.432584e-05 [1.0038038] [1.0862671]\n",
      "1140 2.9978391e-05 [1.0035547] [1.0871663]\n",
      "1160 2.6180782e-05 [1.0033219] [1.0880067]\n",
      "1180 2.286377e-05 [1.0031043] [1.0887921]\n",
      "1200 1.9968324e-05 [1.0029011] [1.0895259]\n",
      "1220 1.7439432e-05 [1.0027112] [1.0902116]\n",
      "1240 1.5229545e-05 [1.0025336] [1.0908527]\n",
      "1260 1.3300107e-05 [1.0023677] [1.0914518]\n",
      "1280 1.16146675e-05 [1.0022126] [1.0920116]\n",
      "1300 1.0143236e-05 [1.0020678] [1.0925347]\n",
      "1320 8.858535e-06 [1.0019324] [1.0930237]\n",
      "1340 7.736039e-06 [1.0018058] [1.0934807]\n",
      "1360 6.755899e-06 [1.0016875] [1.0939076]\n",
      "1380 5.899562e-06 [1.001577] [1.0943066]\n",
      "1400 5.1525913e-06 [1.0014738] [1.0946794]\n",
      "1420 4.5003662e-06 [1.0013773] [1.0950274]\n",
      "1440 3.930267e-06 [1.0012871] [1.0953531]\n",
      "1460 3.4319207e-06 [1.0012028] [1.0956575]\n",
      "1480 2.997529e-06 [1.0011241] [1.0959418]\n",
      "1500 2.6176972e-06 [1.0010505] [1.0962075]\n",
      "1520 2.2863385e-06 [1.0009817] [1.0964559]\n",
      "1540 1.9965921e-06 [1.0009174] [1.096688]\n",
      "1560 1.7437326e-06 [1.0008574] [1.0969049]\n",
      "1580 1.5228852e-06 [1.0008012] [1.0971074]\n",
      "1600 1.3300698e-06 [1.0007488] [1.0972967]\n",
      "1620 1.1615374e-06 [1.0006998] [1.0974737]\n",
      "1640 1.0144786e-06 [1.0006539] [1.0976391]\n",
      "1660 8.8603446e-07 [1.0006112] [1.0977936]\n",
      "1680 7.7382265e-07 [1.0005713] [1.097938]\n",
      "1700 6.7607266e-07 [1.0005338] [1.0980729]\n",
      "1720 5.902216e-07 [1.0004989] [1.098199]\n",
      "1740 5.1562125e-07 [1.0004662] [1.0983169]\n",
      "1760 4.5032812e-07 [1.0004357] [1.0984272]\n",
      "1780 3.9328233e-07 [1.0004071] [1.0985299]\n",
      "1800 3.4353747e-07 [1.0003806] [1.0986261]\n",
      "1820 2.9993953e-07 [1.0003557] [1.0987161]\n",
      "1840 2.6198973e-07 [1.0003324] [1.0988002]\n",
      "1860 2.288908e-07 [1.0003107] [1.0988785]\n",
      "1880 1.9995309e-07 [1.0002904] [1.0989519]\n",
      "1900 1.7469776e-07 [1.0002712] [1.0990204]\n",
      "1920 1.525732e-07 [1.0002537] [1.0990845]\n",
      "1940 1.3328064e-07 [1.0002369] [1.0991443]\n",
      "1960 1.16293585e-07 [1.0002215] [1.0992004]\n",
      "1980 1.0162171e-07 [1.0002071] [1.0992525]\n",
      "2000 8.878733e-08 [1.0001935] [1.0993015]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "# Our hypothesis XW+b\n",
    "hypothesis = X * W + b\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line with new training data\n",
    "for step in range(2001):\n",
    "   cost_val, W_val, b_val, _ = sess.run([cost, W, b, train],\n",
    "       feed_dict={X: [1, 2, 3, 4, 5], \n",
    "                  Y: [2.1, 3.1, 4.1, 5.1, 6.1]})\n",
    "   if step % 20 == 0:\n",
    "       print(step, cost_val, W_val, b_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "print(sess.run(hypothesis, \n",
    "                   feed_dict={X: [1.5, 3.5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.6661 - accuracy: 0.8307\n",
      "## training loss and acc ##\n",
      "[0.6661251970132192]\n",
      "[0.83068335]\n",
      "10000/10000 [==============================] - 1s 81us/step\n",
      "## evaluation loss and_metrics ##\n",
      "[0.3701829928278923, 0.9009000062942505]\n",
      "## yhat ##\n",
      "[[4.19762218e-04 3.75791728e-06 3.26603447e-04 3.13470955e-03\n",
      "  5.43425631e-05 2.71498109e-04 1.57324007e-06 9.90187585e-01\n",
      "  1.15611176e-04 5.48456144e-03]]\n"
     ]
    }
   ],
   "source": [
    "# 0. 사용할 패키지 불러오기\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "# 1. 데이터셋 생성하기\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit(x_train, y_train, epochs=1, batch_size=32)\n",
    "\n",
    "# 5. 학습과정 살펴보기\n",
    "print('## training loss and acc ##')\n",
    "print(hist.history['loss'])\n",
    "# print(hist.history['acc'])\n",
    "print(hist.history['accuracy'])\n",
    "\n",
    "# 6. 모델 평가하기\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=32)\n",
    "print('## evaluation loss and_metrics ##')\n",
    "print(loss_and_metrics)\n",
    "\n",
    "# 7. 모델 사용하기\n",
    "xhat = x_test[0:1]\n",
    "yhat = model.predict(xhat)\n",
    "print('## yhat ##')\n",
    "print(yhat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
